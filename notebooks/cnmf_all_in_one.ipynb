{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cNMF in `cellarium-ml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stephen Fleming, Yang Xu\n",
    "\n",
    "2025.07.31\n",
    "\n",
    "The `cellarium-ml` project:\n",
    "\n",
    "https://github.com/cellarium-ai/cellarium-ml\n",
    "\n",
    "The specific implementation of cNMF we are actively working on:\n",
    "\n",
    "https://github.com/cellarium-ai/cellarium-ml/pull/196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "`cellarium-ml` implements a variety of algorithms in a way that is scalable to hundreds of millions of cells and beyond.\n",
    "This notebook provides a demo run of Cellarium's implementation of consensus NMF (cNMF).\n",
    "The specific algorithm for NMF is based on \"Online learning for matrix factorization and sparse coding\" by Mairal, Bach, Ponce, and Sapiro (JMLR 2010).\n",
    "\n",
    "## This notebook\n",
    "\n",
    "This notebook shows an end-to-end cNMF run in `cellarium-ml`, starting with h5ad files and ending with results.\n",
    "There are several steps involved.\n",
    "\n",
    "## Description of analysis steps\n",
    "\n",
    "1. Compute highly-variable genes.\n",
    "\n",
    "2. Run cNMF on selected highly-variable genes.\n",
    "\n",
    "3. Interactive plotting in this notebook to help determine optimal number of programs `k`, and a \n",
    "   `density_threshold` and `local_neighborhood_size` for the consensus step.\n",
    "\n",
    "4. Computing consensus factors.\n",
    "\n",
    "5. (Optional) Computing per-cell factor loadings.\n",
    "\n",
    "6. (Optional) Re-computing the `k` factor definitions using all genes (not just highly-variable genes).\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- a lits of filepaths to h5ad files: can be local or in a google bucket (or at some URL)\n",
    "    - ideally the h5ad files would be from an extracted curriculum from `cellarium-nexus`, but these files can be any h5ad files\n",
    "        - until [#324](https://github.com/cellarium-ai/cellarium-ml/issues/324) is resolved, the h5ad files\n",
    "          should be limited in size to what can fit in memory\n",
    "\n",
    "## Outputs (work in progress... not complete)\n",
    "\n",
    "- anndata object for all cells (with an empty count matrix) containing:\n",
    "    - `adata.obsm[\"X_cnmf_k20\"]`: (cell, k) matrix of per-cell factor loadings (for the `k = 20` decomposition)\n",
    "    - `adata.obsp[\"cnmf_k20_factors_hvg\"]`: (gene, k) matrix of definitions of each of the `k` consensus programs\n",
    "        - from the initial cNMF fit: all non-highly-variable genes have weight zero\n",
    "    - `adata.obsp[\"cnmf_k20_factors_hvg_tpm\"]`: (gene, k) matrix of definitions of each of the `k` consensus programs\n",
    "        - same as above but weights are recomputed to represent TPM values via a refitting step\n",
    "    - `adata.obsp[\"cnmf_k20_factors\"]`: (gene, k) matrix of definitions of each of the `k` consensus programs\n",
    "        - computed by refitting cell loadings from `adata.obsp[\"cnmf_k20_factors_hvg\"]` by refitting the dataset including all genes\n",
    "    - `adata.obsp[\"cnmf_k20_factors_tpm\"]`: (gene, k) matrix of definitions of each of the `k` consensus programs\n",
    "        - same as above but weights are recomputed to represent TPM values via a refitting step\n",
    "    - (optionally): all of the above for other choices of `k` as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: You will need to use the `nmf_sf_singlenotebook` branch of `cellarium-ml` on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import numpy as np\n",
    "\n",
    "import cellarium.ml.api\n",
    "import cellarium.ml.data\n",
    "import cellarium.ml.models\n",
    "import cellarium.ml.preprocessing\n",
    "import cellarium.ml.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "\n",
    "# CZI dataset is PBMCs from https://cellxgene.cziscience.com/e/59b69042-47c2-47fd-ad03-d21beb99818f.cxg/\n",
    "\n",
    "h5ad_paths = [\n",
    "    \"https://datasets.cellxgene.cziscience.com/a06a1d9e-b1e8-452a-bf83-8ef6ec1044ec.h5ad\"\n",
    "    # \"https://storage.googleapis.com/dsp-cellarium-cas-public/test-data/test_0.h5ad\",\n",
    "    # \"https://storage.googleapis.com/dsp-cellarium-cas-public/test-data/test_1.h5ad\",\n",
    "    # \"https://storage.googleapis.com/dsp-cellarium-cas-public/test-data/test_2.h5ad\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for demonstration purposes: automatically grab h5ad file paths from a bucket prefix, like data from Nexus\n",
    "\n",
    "try:\n",
    "    example_cellarium_curriculum_h5ad_paths = cellarium.ml.api.h5ad_paths_from_google_bucket(\n",
    "        \"gs://cellarium-nexus-file-system-335649/pipeline/data-extracts/TEST2/extract_files\"\n",
    "    )\n",
    "    print(\"Example of how to grab files from a Nexus curriculum bucket path:\")\n",
    "    print(f\"[{example_cellarium_curriculum_h5ad_paths[0]}, ...]\")\n",
    "except:  # noqa: E722\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellarium data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo we are using the python API for cellarium.  It's also possible to use command line versions of these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5ad_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For remote files over the internet, this next cell can take a minute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = cellarium.ml.CellariumAnnDataDataModule(\n",
    "    dadc=cellarium.ml.data.DistributedAnnDataCollection(\n",
    "        filenames=h5ad_paths, limits=np.cumsum(cellarium.ml.api.get_h5ad_files_n_cells(h5ad_paths))\n",
    "    ),\n",
    "    batch_keys={\n",
    "        \"x_ng\": cellarium.ml.utilities.data.AnnDataField(attr=\"X\", convert_fn=cellarium.ml.utilities.data.densify),\n",
    "        \"var_names_g\": cellarium.ml.utilities.data.AnnDataField(attr=\"var_names\"),\n",
    "        \"obs_names_n\": cellarium.ml.utilities.data.AnnDataField(attr=\"obs_names\"),\n",
    "    },\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    train_size=1.0,\n",
    ")\n",
    "\n",
    "datamodule.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highly variable genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run onepass model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This computes mean and variance per gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gene names to use later (and assume all files have the same genes)\n",
    "\n",
    "var_names_g = cellarium.ml.api.get_h5ad_file_var_names_g(h5ad_paths[0])\n",
    "var_names_g[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model that will be used to compute mean and var of each gene\n",
    "\n",
    "onepass_module = cellarium.ml.CellariumModule(\n",
    "    transforms=[\n",
    "        cellarium.ml.transforms.NormalizeTotal(),\n",
    "        cellarium.ml.transforms.Log1p(),\n",
    "    ],\n",
    "    model=cellarium.ml.models.OnePassMeanVarStd(\n",
    "        var_names_g=cellarium.ml.api.get_h5ad_file_var_names_g(h5ad_paths[0]),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=1,\n",
    "    default_root_dir=\"tmp/onepass\",\n",
    ")\n",
    "trainer.fit(onepass_module, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the onepass model computes a mean and variance per gene\n",
    "\n",
    "mean_g = trainer.model.model.mean_g\n",
    "var_g = trainer.model.model.var_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute hvgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose `n_top_genes` to suit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = cellarium.ml.preprocessing.get_highly_variable_genes(\n",
    "    gene_names=var_names_g,\n",
    "    mean=mean_g,\n",
    "    var=var_g,\n",
    "    n_top_genes=2000,\n",
    ")\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var[\"highly_variable\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the highly variable genes\n",
    "\n",
    "hvg_var_names_g = var.index[var[\"highly_variable\"]]\n",
    "hvg_var_names_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cNMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set things up to run cNMF in cellarium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user's choice for the number of components: must input a python list\n",
    "\n",
    "# k_values = [10, 20, 30]\n",
    "k_values = list(range(3, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user's choice for the number of NMF replicates that should go into consensus\n",
    "\n",
    "nmf_replicates = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get set up for training\n",
    "\n",
    "nmf_model = cellarium.ml.models.NonNegativeMatrixFactorization(\n",
    "    full_g=len(var_names_g),\n",
    "    var_names_hvg=hvg_var_names_g,\n",
    "    k_values=k_values,\n",
    "    r=nmf_replicates,\n",
    ")\n",
    "\n",
    "nmf_module = cellarium.ml.CellariumModule(\n",
    "    cpu_transforms=[cellarium.ml.transforms.Filter(filter_list=hvg_var_names_g)],\n",
    "    model=nmf_model,\n",
    ")\n",
    "\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "trainer_nmf = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=5,  # this is up for debate, but empirically 5 seems to be enough\n",
    "    default_root_dir=\"tmp/nmf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the data\n",
    "\n",
    "pl.seed_everything(0)  # not required but helps make this notebook reproducible\n",
    "\n",
    "trainer_nmf.fit(nmf_module, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the shape of the NMF gene programs that have been inferred: [replicates, k, genes]\n",
    "\n",
    "for k in nmf_model.k_values:\n",
    "    print(getattr(nmf_model, f\"D_{k}_rkg\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up to explore outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a helper class that facilitates downstream analysis steps. Here we instantiate it and use it to get various outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellarium.ml.models.nmf import NMFOutput\n",
    "\n",
    "nmf_output = NMFOutput(\n",
    "    nmf_module=nmf_module,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default k-selection plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what Kotliar cNMF would produce with default values for `local_neighborhood_size=0.3` and `density_threshold=0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_output.default_k_selection_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute consensus factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step requires hyperparamter choices.\n",
    "\n",
    "The way the Kotliar cNMF demo notebook works, you first select a `k` of interest and make these choices for that particular `k`.\n",
    "\n",
    "Let's start by picking a k-value and looking at what Kotliar calls the \"local density histogram\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_output.plot_density_histograms(k_values=[best_k], local_neighborhood_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (optional) re-compute consensus D for certain k-values, given hyperparamter choices\n",
    "\n",
    "density_threshold = 0.1  # change this threshold if desired based on the histogram above: idea is to remove outliers\n",
    "local_neighborhood_size = 0.3  # this is a default that Kotliar leaves fixed in tutorials\n",
    "\n",
    "nmf_output.compute_consensus_factors(\n",
    "    k_values=[best_k],\n",
    "    density_threshold=density_threshold,\n",
    "    local_neighborhood_size=local_neighborhood_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one key for each k-value\n",
    "\n",
    "nmf_output.consensus.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each k-value has a few things computed: these get updated if you re-compute consensus for a particular k value\n",
    "\n",
    "list(nmf_output.consensus[best_k].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the consensus matrix for a particular k\n",
    "\n",
    "nmf_output.consensus[best_k][\"consensus_D_kg\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clustermap plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we again experiment with different `density_threshold` values. Plotting the clustermap with different `density_threshold` values actually re-computes consensus for that particular `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nmf_output.plot_clustermap(k=best_k, density_threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_output.plot_clustermap(k=best_k, density_threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute reconstruction error at each k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration here in case you ever want to run this separately, but it gets run automatically as part of `nmf_output.default_k_selection_plot()`.\n",
    "\n",
    "Technically the reconstruction error does depend on hyperparamter choices, because it depends on the consensus programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to calculate the reconstruction error by going through the whole dataset: this can take time\n",
    "\n",
    "nmf_output.calculate_reconstruction_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other versions of the k-selection plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kotliar does not demo this, but the k-selection plot itself depends on the values of `density_threshold` and `local_neighborhood_size`.\n",
    "\n",
    "In principle, you could choose different hyperparameters for each `k`, run `nmf_output.compute_consensus_factors(k, <your selected params here>)` on all the `k`, and then re-run `nmf_output.calculate_reconstruction_error()` and re-create the k-selection plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nmf_output.k_selection_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the stability skyrocketed for `k=best_k` after we filtered at a different threshold?  :)\n",
    "\n",
    "Different thresholds for different `k` hardly seems fair... unless you were to optimize the threshold for each `k` individually..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down a rabbit hole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know, one guiding principle for this process could be the following... for each `k`, automatically choose a (reasonable) `density_threshold` that maximizes the stability for the given `k`. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_output.maximal_stability_k_selection_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results of this kind of automatic choosing of density_threshold\n",
    "# note that the call to plot_clustermap() recomputes consensus, so it's important to specify the computed value\n",
    "\n",
    "for k in [7, 11]:  # nmf_output.consensus:\n",
    "    nmf_output.plot_clustermap(k=k, density_threshold=nmf_output.consensus[k][\"density_threshold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The strange thing about the stability metric is that it does not guarantee that there are actually `k` clusters.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute per-cell loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loadings of each factor, computed for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get per-cell factor loadings using the best k: this takes time\n",
    "# `normalize` controls whether the per-cell loadings sum to 1\n",
    "\n",
    "df = nmf_output.compute_loadings(k=best_k, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory could add this information to the anndata object if you had a single object.\n",
    "Here we will assume the dataset might be very large in total, so we will just try to open one h5ad file and add the annotations for those cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = cellarium.ml.data.read_h5ad_file(h5ad_paths[0])\n",
    "adata.layers[\"counts\"] = adata.raw.X.copy()\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cNMF loadings to obsm\n",
    "\n",
    "adata.obsm[\"X_nmf\"] = df.loc[adata.obs_names].values\n",
    "adata.obsm[\"X_nmf\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize factor loadings on a UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, if you have scanpy installed in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(5, 5), fontsize=14, vector_friendly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, layer=\"counts\", flavor=\"seurat_v3\", n_top_genes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = adata.layers[\"counts\"].copy()\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "# sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, use_highly_variable=True)\n",
    "sc.pp.neighbors(adata, method=\"umap\", metric=\"cosine\", n_pcs=10)\n",
    "sc.tl.umap(adata)\n",
    "adata.obsm[\"X_umap_counts\"] = adata.obsm[\"X_umap\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put these in obs for plotting\n",
    "\n",
    "for k in range(adata.obsm[\"X_nmf\"].shape[1]):\n",
    "    adata.obs[f\"nmf_{k}\"] = adata.obsm[\"X_nmf\"][:, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(\n",
    "    adata, basis=\"umap_counts\", color=[\"disease_original\", \"Cell.group\", \"nmf_0\", \"nmf_1\"], color_map=\"Oranges\", ncols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=\"umap_counts\", color=[f\"nmf_{i}\" for i in range(2, best_k)], color_map=\"Oranges\", ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a UMAP derived from the NMF components\n",
    "\n",
    "sc.pp.neighbors(adata, use_rep=\"X_nmf\", method=\"umap\", metric=\"cosine\")\n",
    "sc.tl.umap(adata)\n",
    "adata.obsm[\"X_umap_nmf\"] = adata.obsm[\"X_umap\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=\"umap_nmf\", color=[\"Cell.group\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely a bit wonky, but also definitely picking up on cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=\"umap\", color=[\"disease_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a random exploration for example\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "celltype_group = \"CD14+ Monocyte\"\n",
    "y = \"nmf_1\"\n",
    "sns.boxplot(\n",
    "    data=adata.obs[adata.obs[\"Cell.group\"] == celltype_group],\n",
    "    x=\"disease_original\",\n",
    "    y=y,\n",
    "    order=[\"Healthy\", \"COVID-19 Mild/Remission\", \"COVID-19 Severe\"],\n",
    ")\n",
    "plt.gca().set_xticklabels(plt.gca().get_xticklabels(), rotation=60)\n",
    "plt.title(celltype_group)\n",
    "plt.ylabel(\"Per-cell loadings of \" + y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just look at some of the genes involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_output.nmf_module.model.var_names_hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_name_lookup = adata.var[\"feature_name\"].to_dict()\n",
    "\n",
    "factor_df = pd.DataFrame(\n",
    "    nmf_output.consensus[best_k][\"consensus_D_kg\"].t().numpy(), index=nmf_output.nmf_module.model.var_names_hvg\n",
    ")\n",
    "factor_df[\"gene_name\"] = factor_df.index.map(gene_name_lookup)\n",
    "factor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df.sort_values(by=1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df.sort_values(by=2, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df.sort_values(by=5, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df.sort_values(by=6, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project factors back to all genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now refit for all genes, not just the highly variable genes. In cNMF this involves solving an auxiliary linear regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results as a summary anndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be packaged up into an anndata object if desired, and perhaps saved that way as an h5ad file.\n",
    "\n",
    "Here we omit the actual count matrix, since in theory it is too big to fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "cellarium",
   "name": "common-cu122.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu122:m121"
  },
  "kernelspec": {
   "display_name": "cellarium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
